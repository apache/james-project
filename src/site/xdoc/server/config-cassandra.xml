<?xml version="1.0"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  "License"); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.    
-->
<document>

 <properties>
  <title>Apache James Server 3 - Cassandra Configuration</title>
 </properties>

<body>

  <section name="Cassandra Configuration">
      <p>This configuration file allow setting some configuration properties in conjunction to
          Cassandra driver native configuration.</p>

      <p>Consult <a href="https://github.com/apache/james-project/blob/master/server/apps/distributed-app/sample-configuration/cassandra.properties">cassandra.properties</a> to get some examples and hints.</p>

      <p>Consult <a href="https://github.com/apache/james-project/blob/master/server/apps/distributed-app/sample-configuration/cassandra-driver.conf">cassandra-driver.conf</a> to get some examples and hints regarding native driver configuration.</p>

      <p>Cassandra native configuration allows configuring SSL, timeouts, logs and metrics as well as execution profiles.</p>

      <p>Note: Cassandra is only available with Guice wiring (cassandra-guice and cassandra-guice-ldap).</p>

      <dl>
        <dt><strong>cassandra.nodes</strong></dt>
        <dd>List of some nodes of the cassandra's cluster in following format host:port or host, if the port is not specified we use 9042</dd>

        <dt><strong>cassandra.keyspace.create</strong></dt>
        <dd>Indicate if the keyspace should be created by James. Optional, default value: <b>false</b><br />
            If set to true James will attempt to create the keyspace when starting up.<br />
        </dd>

        <dt><strong>cassandra.keyspace</strong></dt>
        <dd>Is the name of the keyspace used by James. Optional, default value: <b>apache_james</b></dd>

        <dt><strong>cassandra.user</strong></dt>
        <dd>Username used as a credential for contacting Cassandra cluster. Optional, default is absent,
          required if <strong>cassandra.password</strong> is supplied</dd>

        <dt><strong>cassandra.password</strong></dt>
        <dd>Password used as a credential for contacting Cassandra cluster. Optional, default is absent,
          required if <strong>cassandra.user</strong> is supplied</dd>

        <dt><strong>cassandra.replication.factor</strong></dt>
        <dd>Is the replication factor used upon keyspace creation. Modifying this property while the keyspace already exists
        will have no effect. Optional. Default value 1.</dd>

        <dt><strong>mailbox.read.repair.chance</strong></dt>
        <dd>Optional. Defaults to 0.1 (10% chance).<br/> Must be between 0 and 1 (inclusive). Controls the probability of doing a read-repair upon mailbox read.</dd>
        <dt><strong>mailbox.counters.read.repair.chance.max</strong></dt>
        <dd>Optional. Defaults to 0.1 (10% chance).<br/>
            Must be between 0 and 1 (inclusive). Controls the probability of doing a read-repair upon mailbox counters read.<br/>
            Formula: read_repair_chance = min(mailbox.counters.read.repair.chance.max, (100/unseens)*mailbox.counters.read.repair.chance.one.hundred)
        </dd>
        <dt><strong>mailbox.counters.read.repair.chance.one.hundred</strong></dt>
        <dd>Optional. Defaults to 0.01 (1% chance).<br/>
            Must be between 0 and 1 (inclusive). Controls the probability of doing a read-repair upon mailbox counters read.<br/>
            Formula: read_repair_chance = min(mailbox.counters.read.repair.chance.max, (100/unseens)*mailbox.counters.read.repair.chance.one.hundred)
        </dd>
        <dt><strong>mailbox.max.retry.acl</strong></dt>
        <dd>Optional. Defaults to 1000.<br/> Controls the number of retries upon Cassandra ACL updates.</dd>
        <dt><strong>mailbox.max.retry.modseq</strong></dt>
        <dd>Optional. Defaults to 100000.<br/> Controls the number of retries upon Cassandra ModSeq generation.</dd>
        <dt><strong>mailbox.max.retry.uid</strong></dt>
        <dd>Optional. Defaults to 100000.<br/> Controls the number of retries upon Cassandra Uid generation.</dd>
        <dt><strong>mailbox.max.retry.message.flags.update</strong></dt>
        <dd>Optional. Defaults to 1000.<br/> Controls the number of retries upon Cassandra flags update, in MessageMapper.</dd>
        <dt><strong>mailbox.max.retry.message.id.flags.update</strong></dt>
        <dd>Optional. Defaults to 1000.<br/> Controls the number of retries upon Cassandra flags update, in MessageIdMapper.</dd>
        <dt><strong>chunk.size.message.read</strong></dt>
        <dd>Optional. Defaults to 100.<br/> Controls the number of messages to be retrieved in parallel.</dd>
        <dt><strong>chunk.size.expunge</strong></dt>
        <dd>Optional. Defaults to 50.<br/> Controls the number of messages to be expunged in parallel.</dd>
        <dt><strong>mailbox.blob.part.size</strong></dt>
        <dd>Optional. Defaults to 102400 (100KB).<br/> Controls the size of blob parts used to store messages.</dd>

        <dt><strong>mailbox.read.strong.consistency</strong></dt>
        <dd>Optional. Boolean, defaults to true. Disabling should be considered experimental.
            If enabled, regular consistency level is used for read transactions for mailbox. Not doing so might result
            in stale reads as the system.paxos table will not be checked for latest updates. Better performance are expected
            by turning it off. Note that reads performed as part of write transactions are always performed with a strong
            consistency.</dd>

        <dt><strong>message.read.strong.consistency</strong></dt>
        <dd>Optional. Boolean, defaults to true. Disabling should be considered experimental.
            If enabled, regular consistency level is used for read transactions for message. Not doing so might result
            in stale reads as the system.paxos table will not be checked for latest updates. Better performance are expected
            by turning it off. Note that reads performed as part of write transactions are always performed with a strong
            consistency.</dd>

        <dt><strong>message.write.strong.consistency.unsafe</strong></dt>
        <dd>Optional. Boolean, defaults to true. Disabling should be considered experimental and unsafe.
            If disabled, Lightweight transactions will no longer be used upon messages operation (table `imapUidTable`).
            As message flags updates relies so far on a read-before-write model, it exposes yourself to data races leading to
            potentially update loss. Better performance are expected
            by turning it off. Reads performed as part of write transaction are also performed with a relaxed consistency.</dd>

        <dt><strong>cassandra.local.dc</strong></dt>
        <dd>Optional. Allows specifying the local DC as part of the load balancing policy. Specifying it
            would result in the use of <code>new TokenAwarePolicy(DCAwareRoundRobinPolicy.builder().withLocalDc(value).build())</code> as a LoadBalancingPolicy.
            This value is useful in a multi-DC Cassandra setup. Be aware of limitations of multi-DC setups for James.
            Not specifying this value results in the driver's default load balancing policy to be used.</dd>
        <dt><strong>optimistic.consistency.level.enabled</strong></dt>
        <dd>Optional. Defaults to false. Allows specifying consistency level ONE for reads in Cassandra BlobStore.
            Falls back to default read consistency level if the blob is missing.</dd>
        <dt><strong>mailrepository.strong.consistency</strong></dt>
        <dd>Optional. Defaults to true. Allows not to use lightweight transactions in CassandraMailRepository.
            If disabled we implement an idempotent behaviour (duplicates are overridden, missing entries upon deletes are ignored).</dd>
        <dt><strong>acl.enabled</strong></dt>
        <dd>Optional. Boolean, defaults to true. Allows disabling ACLs: if set to false, delegation will fail and users will only
            have access to the mailboxes they own. ACLs can represent a high volume of requests. If you do not propose mailbox sharing
            features to your users, you can consider disabling them in order to improve performance.</dd>
        <dt><strong>email.change.ttl</strong></dt>
        <dd>Optional. Duration, default to 60 days. Cassandra Time-to-live for Email change records.
            Setting time-to-live to zero means refusing to use time-to-live on email changes.</dd>
        <dt><strong>mailbox.change.ttl</strong></dt>
        <dd>Optional. Duration, default to 60 days. Cassandra Time-to-live for Mailbox change records.
            Setting time-to-live to zero means refusing to use time-to-live on mailbox changes.</dd>
      </dl>


<p>If you want more explanation about Cassandra configuration, you should visit the dedicated <a href="http://docs.datastax.com/en/cassandra/2.1/cassandra/gettingStartedCassandraIntro.html">documentation</a>.</p>

  </section>

  <section name="Cassandra migration process">
    <p>Cassandra upgrades implies the creation of a new table. Thus restarting James is needed, as new tables are created on restart.</p>

    <p>Once done, we ship code that tries to read from new tables, and if not possible backs up to old tables. You can thus safely run
    without running additional migrations.</p>

    <p>On the fly migration can be enabled. However, one might want to force the migration in a controlled fashion, and update
    automatically current schema version used (assess in the database old versions is no more used, as the corresponding tables are empty).
    Note that this process is safe: we ensure the service is not running concurrently on this James instance, that it does not bump
    version upon partial failures, that race condition in version upgrades will be idempotent, etc...</p>

    <p>These schema updates can be triggered by <a href="manage-webadmin.html">webadmin</a> using the Cassandra backend.</p>

    <p>Note that currently the progress can be tracked by logs.</p>

    Here are the implemented migrations:

    <subsection name="From V1 to V2">

      <p>Last support on releases 3.5.0</p>

      <p>Migration tag on git repository: <a href="https://github.com/apache/james-project/releases/tag/cassandra_migration_v1_to_v2">cassandra_migration_v1_to_v2</a></p>

      <p>Goal is to create a messageV2 table that aims at replacing message table. Message table is both storing message
        metadata and blobs. It have been proven inefficient. Instead version 2 is chunking message blobs and storing it
        in an other table. The migration process involves moving all messages from message table to messageV2 table
        (contains only metadata) and blobs / blobParts tables.</p>

      <p>Read more about this migration <a href="https://medium.com/p/7e8607eb3c4f">here</a>.</p>

      <p>Summary of available options for this migration:</p>

      <dl>
        <dt><strong>migration.v1.v2.on.the.fly</strong></dt>
        <dd>Only available on tag cassandra_migration_v1_to_v2. Optional. Defaults to false.<br/> Controls wether v1 to v2 migration should be run on the fly.</dd>
        <dt><strong>migration.v1.v2.thread.count</strong></dt>
        <dd>Only available on tag cassandra_migration_v1_to_v2. Optional. Defaults to 2.<br/> Controls the number of threads used to asynchronously migrate from v1 to v2.</dd>
        <dt><strong>migration.v1.v2.queue.length</strong></dt>
        <dd>Only available on tag cassandra_migration_v1_to_v2. Optional. Defaults to 1000.<br/> Controls the queue size of v1 to v2 migration task. Drops when full.</dd>
        <dt><strong>migration.v1.read.fetch.size</strong></dt>
        <dd>Only available on tag cassandra_migration_v1_to_v2. Optional. Defaults to 10.<br/> Controls the fetch size of the request to retrieve all messages stored in V1 during the migration process.</dd>
      </dl>

    </subsection>

    <subsection name="From V2 to V3">

      <p>Last support on releases 3.5.0</p>

      <p>Migration tag on git repository: <a href="https://github.com/apache/james-project/releases/tag/cassandra_migration_v2_to_v3">cassandra_migration_v2_to_v3</a></p>

      <p>Goal is to drop <b>message</b> table. After this migration, one can manually delete this table.</p>

    </subsection>

    <subsection name="From V3 to V4">

      <p>Last support on releases 3.5.0</p>

      <p>Migration tag on git repository: <a href="https://github.com/apache/james-project/releases/tag/cassandra_migration_v3_to_v4">cassandra_migration_v3_to_v4</a></p>

      <p>Goal is to store attachments in the blob tables.</p>

      <p>Summary of available options for this migration:</p>

      <dl>
        <dt><strong>attachment.v2.migration.read.timeout</strong></dt>
        <dd>Optional. Defaults to one day.<br/> Controls how many milliseconds before the read on attachment v1 time out.</dd>
      </dl>

    </subsection>

    <subsection name="From V4 to V5">

      <p>Last support on releases 3.5.0</p>

      <p>Migration tag on git repository: <a href="https://github.com/apache/james-project/releases/tag/cassandra_migration_v4_to_v5">cassandra_migration_v4_to_v5</a></p>

      <p>Goal is to store attachment ids in the separated AttachmentMessageId table.</p>

      <p>Summary of available options for this migration:</p>

      <dl>
        <dt><strong>message.attachmentids.read.timeout</strong></dt>
        <dd>Optional. Defaults to one day.<br/> Controls how many milliseconds before the read attachment ids on message time out.</dd>
      </dl>

    </subsection>

    <subsection name="From V5 to V6">

      <p>Last support on releases 3.6.x</p>

      <p>Goal is to no longer rely on an UDT partition key for mailboxPath tables. Entries will be migrated to mailboxPathV2 table relying on a composite primary key</p>

    </subsection>

    <subsection name="From V6 to V7">

      <p>Last support on releases 3.6.x</p>

      <p>Goal is to populate mapping_sources projection table. This table allows finding the source of a given redirection, which is
      handy for things like mail aliases (I want to list aliases rewritting things to bob). Without this projection table being available,
      (ie we rely on schema version 6 or less) such information is obtained through a full table scan, unoptimized. From schema version 7,
      the optimized projection can safely be used.</p>

    </subsection>

    <subsection name="From V7 to V8">

      <p>Last support on releases 3.6.x</p>

      <p>Add UID_VALIDITY to mailboxPath table in order not to mandate mailbox table reads.</p>

    </subsection>

    <subsection name="From V8 to V9">

      <p>Adopt a more compact representation for message properties.</p>

    </subsection>

    <subsection name="From V9 to V10">

      <p>Handles Mailbox ACL transactionality with event-sourcing. We got read of SERIAL consistency upon reads thus unlocking a
          major performance enhancement.</p>

    </subsection>

    <subsection name="Adding threadId column to message metadata tables">

      <p>Add threadId column to messageIdTable and imapUidTable in order to get a message's threadId.</p>

    </subsection>

  </section>

</body>

</document>
