<?xml version="1.0"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  "License"); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.    
-->
<document>

    <properties>
        <title>Apache James Server 3 - Blob Configuration</title>
    </properties>

    <body>

        <section name="BlobStore Configuration">
            <p>
                BlobStore is the dedicated component to store blobs, non-indexable content.
                James uses the BlobStore for storing blobs which are usually mail contents, attachments, deleted mails...
                You can choose the underlying implementation of BlobStore to fit with your James setup.
                It could be the implementation on top of Cassandra or file storage service like Openstack Swift, AWS S3.

                This configuration is only applicable with Guice products.
            </p>
            <p>
                Consult <a href="https://github.com/apache/james-project/blob/master/server/apps/distributed-app/sample-configuration/blob.properties">blob.properties</a>
                in GIT to get some examples and hints.
            </p>

            <p>
                Blobs storing configuration
            </p>
            <dl>
                <dt><strong>implementation</strong></dt>
                <dd>cassandra: use cassandra based BlobStore</dd>
                <dd>s3: use AWS S3 based BlobStore</dd>
                <dd>file: (experimental) use directly the file system. Useful for legacy architecture based on shared ISCI SANs and/or
                distributed file system with no object store available.</dd>
                <dd><b>WARNING</b>: JAMES-3591 Cassandra is not made to store large binary content, its use will be suboptimal compared to
                    alternatives (namely S3 compatible BlobStores backed by for instance S3, MinIO or Ozone)
                </dd>
                <dd>
                    The generated startup warning log can be deactivated via the <code>cassandra.blob.store.disable.startup.warning</code> environment
                    variable being positioned to <code>false</code>.
                </dd>
                <dt><strong>deduplication.enable</strong></dt>
                <dd>Mandatory. Supported value: true and false.</dd>
                <dd>If you choose to enable deduplication, the mails with the same content will be stored only once.</dd>
                <dd>Warning: Once this feature is enabled, there is no turning back as turning it off will lead to the deletion of all</dd>
                <dd>the mails sharing the same content once one is deleted.</dd>
                <dd>This feature also requires a garbage collector mechanism to effectively drop blobs. A first implementation
                    based on bloom filters can be used and triggered using the WebAdmin REST API. See
                    <a href="manage-webadmin.html#Running_blob_garbage_collection">Running blob garbage collection</a>.
                    In order to avoid concurrency issues upon garbage collection, we slice the blobs in generation, the two more recent
                    generations are not garbage collected.</dd>
                <dd><strong>deduplication.gc.generation.duration</strong></dd>
                <dd>Allow controlling the duration of one generation. Longer implies better deduplication
                    but deleted blobs will live longer. Duration, defaults on 30 days, the default unit is in days.</dd>
                <dd><strong>deduplication.gc.generation.family</strong></dd>
                <dd>Every time the duration is changed, this integer counter must be incremented to avoid
                    conflicts. Defaults to 1.</dd>
                <dd>Upgrade note: If you are upgrading from James 3.5 or older, the deduplication was enabled.</dd>
            </dl>


            <subsection name="Cassandra BlobStore Cache">
                <p>A Cassandra cache can be enabled to reduce latency when reading small blobs frequently.
                    A dedicated keyspace with a replication factor of one is then used.
                    Cache eviction policy is TTL based.
                    Only blobs below a given threshold will be stored.
                    To be noted that blobs are stored within a single Cassandra row, hence a low threshold should be used.
                </p>
                <dl>
                    <dt><strong>cache.enable</strong></dt>
                    <dd>DEFAULT: false, optional, must be a boolean. Whether the cache should be enabled.</dd>
                </dl>
                <dl>
                    <dt><strong>cache.cassandra.ttl</strong></dt>
                    <dd>DEFAULT: 7 days, optional, must be a duration. Cache eviction policy is TTL based. </dd>
                </dl>
                <dl>
                    <dt><strong>cache.sizeThresholdInBytes</strong></dt>
                    <dd>DEFAULT: 8192, optional, must be a positive integer. Unit: bytes.
                        Supported units: bytes, Kib, MiB, GiB, TiB
                        Maximum size of stored objects expressed in bytes.</dd>
                </dl>
            </subsection>
            <subsection name="Encryption choice">
                <p>
                    Data can be optionally encrypted with a symmetric key using AES before being stored in the blobStore. As many user relies
                    on third party for object storage, a compromised third party will not escalate to a data disclosure. Of course, a
                    performance price have to be paid, as encryption takes resources.
                </p>
                <dl>
                    <dt><strong>encryption.aes.enable</strong></dt>
                    <dd>Optional boolean, defaults to false</dd>
                </dl>
                <p>If AES encryption is enabled, then the following properties MUST be present:</p>
                <dl>
                    <dt><strong>encryption.aes.password</strong></dt>
                    <dd>String</dd>
                </dl>
                <dl>
                    <dt><strong>encryption.aes.salt</strong></dt>
                    <dd>Hexadecimal string.</dd>
                </dl>
                <p>If AES encryption is enabled, then the following properties COULD be present:</p>
                <dl>
                    <dt><strong>encryption.aes.private.key.algorithm</strong></dt>
                    <dd>String, defaulting to PBKDF2WithHmacSHA512. Previously was
                        PBKDF2WithHmacSHA1.</dd>
                </dl>

                <p><b>WARNING:</b> Once chosen this choice can not be reverted, all the data is either clear or encrypted. Mixed encryption
                    is not supported.</p>
                <p>
                    Here is an example of how you can generate the above values (be mindful to customize the byte lengths in order to add
                    enough entropy.
                </p>
                <pre>
                    <code>
# Password generation
openssl rand -base64 64

# Salt generation
generate salt with : openssl rand -hex 16
                    </code>
                </pre>
            </subsection>
            <subsection name="ObjectStorage BlobStore Buckets Configuration">
                <dl>
                    <dt><strong>objectstorage.bucketPrefix</strong></dt>
                    <dd>
                        Bucket is an concept in James and similar to Containers in Swift or Buckets in AWS S3.
                        BucketPrefix is the prefix of bucket names in James BlobStore
                    </dd>

                    <dt><strong>objectstorage.namespace</strong></dt>
                    <dd>
                        BlobStore default bucket name. Most of blobs storing in BlobStore are inside the default bucket.
                        Unless a special case like storing blobs of deleted messages.
                    </dd>
                </dl>
            </subsection>
            <subsection name="ObjectStorage Underlying Service Configuration">
                <subsection name="ObjectStorage AWS S3 Configuration">
                    <dl>
                        <dt><strong>objectstorage.s3.endPoint</strong></dt>
                        <dd>S3 service endpoint</dd>

                        <dt><strong>objectstorage.s3.region</strong></dt>
                        <dd>S3 region</dd>

                        <dt><strong>objectstorage.s3.accessKeyId</strong></dt>
                        <dd><a href="https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys">S3 access key id</a></dd>

                        <dt><strong>objectstorage.s3.secretKey</strong></dt>
                        <dd><a href="https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys">S3 access key secret</a></dd>

                        <dt><strong>objectstorage.s3.http.concurrency</strong></dt>
                        <dd>Allow setting the number of concurrent HTTP requests allowed by the Netty driver.</dd>

                        <dt><strong>objectstorage.s3.truststore.path</strong></dt>
                        <dd><i>optional:</i> Verify the S3 server certificate against this trust store file.</dd>

                        <dt><strong>objectstorage.s3.truststore.type</strong></dt>
                        <dd><i>optional:</i> Specify the type of the trust store, e.g. JKS, PKCS12</dd>

                        <dt><strong>objectstorage.s3.truststore.secret</strong></dt>
                        <dd><i>optional:</i> Use this secret/password to access the trust store; default none</dd>

                        <dt><strong>objectstorage.s3.truststore.algorithm</strong></dt>
                        <dd><i>optional:</i> Use this specific trust store algorithm; default SunX509</dd>

                        <dt><strong>objectstorage.s3.trustall</strong></dt>
                        <dd><i>optional:</i>  boolean. Defaults to false. Cannot be set to true with other trustore options. Wether James should validate
                        S3 endpoint SSL certificates.</dd>

                        <dt><strong>objectstorage.s3.read.timeout</strong></dt>
                        <dd><i>optional:</i> HTTP read timeout. duration, default value being second. Leaving it empty relies on S3 driver defaults.</dd>

                        <dt><strong>objectstorage.s3.write.timeout</strong></dt>
                        <dd><i>optional:</i> HTTP write timeout. duration, default value being second. Leaving it empty relies on S3 driver defaults.</dd>

                        <dt><strong>objectstorage.s3.connection.timeout</strong></dt>
                        <dd><i>optional:</i> HTTP connection timeout. duration, default value being second. Leaving it empty relies on S3 driver defaults.</dd>

                        <dt><strong>objectstorage.s3.in.read.limit</strong></dt>
                        <dd><i>optional:</i> Object read in memory will be rejected if they exceed the size limit exposed here. Size, exemple `100M`.
                            Supported units: K, M, G, defaults to B if no unit is specified. If unspecified, big object won't be prevented
                            from being loaded in memory. This settings complements protocol limits.</dd>

                        <dt><strong>objectstorage.s3.upload.retry.maxAttempts</strong></dt>
                        <dd><i>optional:</i> Integer. Default is zero. This property specifies the maximum number of retry attempts allowed for failed upload operations.</dd>

                        <dt><strong>objectstorage.s3.upload.retry.backoffDurationMillis</strong></dt>
                        <dd><i>optional:</i> Long (Milliseconds). Default is 10 (miliseconds).
                            Only takes effect when the "objectstorage.s3.upload.retry.maxAttempts" property is declared.
                            This property determines the duration (in milliseconds) to wait between retry attempts for failed upload operations.
                            This delay is known as backoff. The jitter factor is 0.5</dd>

                    </dl>
                </subsection>
            </subsection>
        </section>

    </body>

</document>
